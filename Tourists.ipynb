{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install libraries"
      ],
      "metadata": {
        "id": "piXqj5iXyPBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --pre pycaret\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "utjJzQIEx6nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Connect to drive"
      ],
      "metadata": {
        "id": "8sbC0G04yKmX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbIGsytSxke4",
        "outputId": "ee2ff673-f92b-4a29-8741-83de8e4fa068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries"
      ],
      "metadata": {
        "id": "rj6WFUUWyIz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import catboost\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "import pycaret\n",
        "from pycaret.classification import *\n",
        "from pycaret.regression import load_model \n",
        "from pycaret.classification import *\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "import pickle\n",
        "import joblib\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pd.set_option(\"display.max_columns\",None )"
      ],
      "metadata": {
        "id": "lz3phvTkx4oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Process Class, batch saving"
      ],
      "metadata": {
        "id": "MgeY-fn-yGun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tourists:\n",
        "    \n",
        "    df_tourists = pd.DataFrame([])\n",
        "    df_uselesses = pd.DataFrame([])\n",
        "    \n",
        "    df_tourists_columns = df_tourists.columns\n",
        "    df_uselesses_columns = df_uselesses.columns\n",
        "    \n",
        "    train = pd.DataFrame([])\n",
        "    test = pd.DataFrame([])\n",
        "    train_label = []\n",
        "    test_label = []\n",
        "    df_Total =  pd.DataFrame([])\n",
        "    df_Total_processed = []\n",
        "    df_Total_processed_label = []\n",
        "    df_Total_labels = []\n",
        "    \n",
        "    categorical_feature_list = []\n",
        "    prediction = []\n",
        "    Probabilities = []\n",
        "    Catboost_model = []\n",
        "    tn=0\n",
        "    fp=0\n",
        "    fn=0\n",
        "    tp=0\n",
        "    Accuracy = -1\n",
        "    Recall =0 \n",
        "    Precision =0\n",
        "    Error_rate =0\n",
        "    adress_convert=''\n",
        "    adress_notconvert=''\n",
        "    \n",
        "    def __init__(self,adress_convert,adress_notconvert):\n",
        "        print(\"Hi Tourists class has been initialized!\")\n",
        "        \n",
        "        self.df_tourists = pd.read_csv(adress_convert)\n",
        "        self.df_uselesses = pd.read_csv(adress_notconvert)\n",
        "        self.df_Total = pd.concat([self.df_tourists, self.df_uselesses])\n",
        "        self.df_Total_processed_label = np.concatenate((np.ones(self.df_tourists.shape[0]), \n",
        "                                                        np.zeros(self.df_uselesses.shape[0])), axis=None)\n",
        "        self.df_Total_processed = self.preprocessf(self.df_Total)\n",
        "        self.df_tourists['label'] = 1\n",
        "        self.df_uselesses['label'] = 0\n",
        "\n",
        "        self.df_Total_labels = self.df_Total_processed\n",
        "        self.df_Total_labels['labels'] = self.df_Total_processed_label\n",
        "        self.df_Total_labels = self.df_Total_labels.sample(frac = 1).reset_index()\n",
        "\n",
        "        \n",
        "        # self.batch_train_dataset(self.df_Total_labels, 5,'save')\n",
        "\n",
        "\n",
        "    def One_Hot_Enc(self, df, column):\n",
        "        \n",
        "        services = pd.get_dummies(df[column].str.split(',', expand=True),\n",
        "                                  prefix=column, prefix_sep='').groupby(level=0, axis=1).max()\n",
        "        df = pd.concat([df, services], axis='columns')\n",
        "        return df\n",
        "    \n",
        "        \n",
        "    def preprocessf(self, df):\n",
        "        \n",
        "        #pivote on services\n",
        "        columns = ['senfs', 'serviceusage', 'topservices' ,'topservicesexc2c', 'businesstags', 'bankscp']\n",
        "        for x in columns:\n",
        "            df = self.One_Hot_Enc(df, x)\n",
        "            \n",
        "         # numerical sex   \n",
        "        cleanup_nums = {\"gender\": {\"Male\": 1, \"Female\": 2}}\n",
        "        df = df.replace(cleanup_nums)  \n",
        "            \n",
        "        #fillna\n",
        "        for x in df.columns:\n",
        "               df[x] = df[x].fillna(0)\n",
        "        \n",
        "         \n",
        "        # len feature\n",
        "        list_len = ['topservices', 'topservicesexc2c', 'businesstags', 'serviceusage', 'senfs', 'bankscp']\n",
        "        for x in list_len:\n",
        "            df['len_'+x] = df[x].apply(lambda x: len(str(x).split(',')))\n",
        "        \n",
        "        # Age feature\n",
        "        today = datetime.date.today()\n",
        "        this_year = int(today.strftime(\"%Y\"))\n",
        "        \n",
        "        list_age = ['firsttrsdateapplication', 'firstappinstalldate', 'birthday']\n",
        "        for x in list_age:\n",
        "            df['age_'+x] = this_year - df[x].str.split('T',expand = True)[0].str.split('-',expand = True)[0].fillna(0).apply(int)\n",
        "            \n",
        "        #drop extra features\n",
        "        df = df.drop(columns = ['Unnamed: 0',\n",
        "                                'uuid', 'ussdid', \n",
        "                                'email', #'name', \n",
        "                                'birthday', 'bankscp',\n",
        "                                'businesstags',        \n",
        "                                'firsttrsdateapplication', 'firstappinstalldate',\n",
        "                                'firstprovince', #'firstregion','secondprovince', 'secondregion',\n",
        "                                'maskedmobilenumber', 'maskednationalid',\n",
        "                                'senfs', 'serviceusage', 'topservices', 'topservicesexc2c'])\n",
        "        #integer\n",
        "        cat = ['name','firstregion','secondprovince', 'secondregion']\n",
        "        \n",
        "        for x in [x for x in df.columns if (x not in cat)]:\n",
        "               df[x] = df[x].apply(int)\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    \n",
        "    def split_test(self, df_X, df_Y):\n",
        "        \n",
        "        self.train, self.test, self.train_label, self.test_label = train_test_split(df_X, df_Y, \n",
        "                                                                                     random_state=104, \n",
        "                                                                                     test_size=0.25, shuffle=True)  \n",
        "        \n",
        "        return (self.train, self.test, self.train_label, self.test_label)\n",
        "        \n",
        "\n",
        "    def Evaluation(self):\n",
        "\n",
        "        self.tn, self.fp, self.fn, self.tp =  confusion_matrix(self.prediction, self.test_label).ravel() \n",
        "        self.Recall =self.tp / (self.tp + self.fn)\n",
        "        self.Precision = self.tp / (self.tp + self.fp)\n",
        "        self.Error_rate = (self.fp+self.fn)/(self.tp+self.tn+self.fp+self.fn)\n",
        "        self.Accuracy = (self.tp+self.tn)/(self.tp+self.tn+self.fp+self.fn)\n",
        "        print(\"\\nAccuracy\", self.Accuracy)\n",
        "        print(\"\\nError_rate\", self.Error_rate)\n",
        "        print(\"\\nRecall\", self.Recall)\n",
        "        print(\"\\nPrecision\", self.Precision)\n",
        "        return 0\n",
        "    \n",
        "    def prediction_model(self):\n",
        "            \n",
        "        self.split_test(self.df_Total_processed, self.df_Total_processed_label)    \n",
        "        \n",
        "        categorical_feature_list = [ self.train.columns.get_loc('name'), self.train.columns.get_loc('firstregion'), \n",
        "                                    self.train.columns.get_loc('secondprovince'), self.train.columns.get_loc('secondregion')] \n",
        "           \n",
        "        # Initialize CatBoostClassifier\n",
        "        model = CatBoostClassifier(iterations=2,\n",
        "                                   learning_rate=1,\n",
        "                                   depth=2)\n",
        "        \n",
        "        # Fit model\n",
        "        self.Catboost_model = model.fit(self.train, self.train_label, categorical_feature_list)\n",
        "                                        #verbose=False,plot=True)\n",
        "        \n",
        "        self.Catboost_model.save_model('catboost') \n",
        "\n",
        "        # Get predicted classes\n",
        "        self.prediction = model.predict(self.test)\n",
        "        \n",
        "        # Get predicted probabilities for each class\n",
        "        self.Probabilities = model.predict_proba(self.test)\n",
        "        \n",
        "        # Get predicted RawFormulaVal\n",
        "        preds_raw = model.predict(self.test, prediction_type='RawFormulaVal') \n",
        "        \n",
        "        self.Evaluation()\n",
        "        return model\n",
        "\n",
        "\n",
        "    def Pycaret_model(self):\n",
        "      \n",
        "        self.df_total = df_total.sample(frac = 1).reset_index()\n",
        "        # prediction_model. \n",
        "        \n",
        "       # Save the model as a pickle in a file\n",
        "        joblib.dump(knn, 'filename.pkl')\n",
        "  \n",
        "        # Load the model from the file\n",
        "        knn_from_joblib = joblib.load('filename.pkl')\n",
        "  \n",
        "        # Use the loaded model to make predictions\n",
        "        knn_from_joblib.predict(X_test)    \n",
        "\n",
        "        return 0\n",
        "    \n",
        "    def batch_train_dataset(self, dataframe, number_of_batch, task):\n",
        "\n",
        "      batch_size = int(dataframe.shape[0]/number_of_batch)\n",
        "\n",
        "      if task == 'save':\n",
        "        for i in range (1, number_of_batch+1):\n",
        "          name = 'PotentialUser_' + i.__str__() + '_Batch' + '.csv'\n",
        "          dataframe[(i-1)*batch_size: i*batch_size].to_csv(\"/content/drive/My Drive/\" + name, index=False)\n",
        "\n",
        "      if task == 'load':\n",
        "        for i in range (1, number_of_batch+1):\n",
        "          name = r'PotentialUser_' + i.__str__() + '_Batch' + '.csv'\n",
        "          globals()[f\"dataframe_batch{i}\"] = pd.read_csv(\"/content/drive/My Drive/\" + name)\n",
        "      \n",
        "      return 0    "
      ],
      "metadata": {
        "id": "cCIikdAQx9UQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main"
      ],
      "metadata": {
        "id": "j-Rw37EIyEVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " if __name__ == '__main__':  \n",
        "   \n",
        "  a='/content/drive/My Drive/converted_join_cp.csv'\n",
        "  b='/content/drive/My Drive/notconverted_join_cp.csv'\n",
        "\n",
        "  Class = Tourists(a,b)\n",
        "  df = Class.df_Total_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vtbr-3SyDiP",
        "outputId": "bd287e01-e396-424e-ad64-9533658a52a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi Tourists class has been initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pycaret Setups"
      ],
      "metadata": {
        "id": "eeRhj-JAysDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-engineering"
      ],
      "metadata": {
        "id": "e-9SEjwK0RGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = setup(globals()[f\"dataframe_batch{1}\"].drop(columns =['labels']) ,\n",
        "          target = globals()[f\"dataframe_batch{1}\"]['labels'] ,\n",
        "          fix_imbalance = True ,\n",
        "          remove_outliers = True ,\n",
        "          normalize = True , \n",
        "          normalize_method = 'robust' ,\n",
        "          bin_numeric_features = ['age_birthday'] ,\n",
        "          feature_selection = True ,\n",
        "          remove_multicollinearity  = True , \n",
        "          pca = True , \n",
        "          use_gpu = True , \n",
        "          profile = True) "
      ],
      "metadata": {
        "id": "farWaTaIyngf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best = compare_models()"
      ],
      "metadata": {
        "id": "E7Xl4oU52TPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(best)"
      ],
      "metadata": {
        "id": "9NlTOb1b2ggK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(best)"
      ],
      "metadata": {
        "id": "xoIoXv4T2hEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.regression import load_model \n",
        "\n",
        "Ridge_Classifier = create_model('ridge') \n",
        "save_model(Ridge_Classifier, 'saved_ridge_model') \n",
        "saved_ridge = load_model('saved_ridge_model') "
      ],
      "metadata": {
        "id": "M5p2IliW2Y7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Catboost"
      ],
      "metadata": {
        "id": "ZzjFUbcT0sAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://catboost.ai/en/docs/features/visualization_jupyter-notebook\n"
      ],
      "metadata": {
        "id": "r_HQSA740uBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_X = df.drop(columns = ['labels'])\n",
        "df_Y = df['labels']\n",
        "train, test, train_label, test_label = train_test_split(df_X, df_Y,\n",
        "                                                        random_state=104, \n",
        "                                                        test_size=0.25,\n",
        "                                                        shuffle=True)  \n",
        "        \n",
        "categorical_feature_list = [ train.columns.get_loc('name'), train.columns.get_loc('firstregion'), \n",
        "                              train.columns.get_loc('secondprovince'), train.columns.get_loc('secondregion')] \n",
        "           \n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier(iterations=2,\n",
        "                          learning_rate=1,\n",
        "                          depth=2)\n",
        "        \n",
        "# Fit model\n",
        "Catboost_model = model.fit(df_X, df_Y, categorical_feature_list)\n",
        "                                        #verbose=False,plot=True)\n",
        "        \n",
        "Catboost_model.save_model('/content/drive/My Drive/catboost',\n",
        "           format=\"cbm\",\n",
        "           export_parameters=None,\n",
        "           pool=None)\n",
        "\n",
        "# # Get predicted classes\n",
        "prediction = model.predict(test)\n",
        "        \n",
        "# # Get predicted probabilities for each class\n",
        "# Probabilities = model.predict_proba(test)"
      ],
      "metadata": {
        "id": "IHRqBpQ3zN2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(predictions['prediction_label'], Y_test)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                             display_labels=[0,1])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "Xkg7F5lY3EYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "IXbuoQH23ODu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quadratic Discriminant Analysis"
      ],
      "metadata": {
        "id": "mRymRS_v5jV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = Y_test\n",
        "y_pred = predictions_qda['prediction_label']\n",
        "target_names = ['class1','class2']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "llKjJKii5jBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression"
      ],
      "metadata": {
        "id": "FYTVFcJF5kNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = Y_test\n",
        "y_pred = predictions_lr['prediction_label']\n",
        "target_names = ['class1','class2']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "P43dj_zs5jzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Catboost"
      ],
      "metadata": {
        "id": "rrDG_DVd5lVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = df_Y\n",
        "y_pred = predictions_catboost\n",
        "\n",
        "target_names = ['class1','class2']\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "GXjoZ_tN5k6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load models"
      ],
      "metadata": {
        "id": "-WRL14ST4T7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CP_chunk_processed = preprocessf(P)\n",
        "CP_chunk_processed.to_csv('/content/drive/My Drive/CPchunk_processed_main', index = False) \n",
        "df_chunk = pd.read_csv('/content/drive/My Drive/CPchunk_processed_main') "
      ],
      "metadata": {
        "id": "R0fYk2j-47hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load saved models"
      ],
      "metadata": {
        "id": "xyd0wg0F5Ojg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import catboost as cb\n",
        "\n",
        "lists = ['index', 'businesstags1005', 'businesstags1015', 'businesstags1017', 'bankscp400046', 'bankscp400234', 'bankscp505809', 'bankscp639217', 'bankscp983254']\n",
        "for x in lists:\n",
        "  df_chunk[x]=0\n",
        "\n",
        "qda = load_model('/content/drive/My Drive/qda')\n",
        "lr = load_model('/content/drive/My Drive/lr')\n",
        "# catboost = load_model('/content/drive/My Drive/catboost')\n",
        "model = CatBoostClassifier()\n",
        "catboost=model.load_model(\"/content/drive/My Drive/catboost\")\n"
      ],
      "metadata": {
        "id": "ZRthh7b34QtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the 1M chunk of customer profile"
      ],
      "metadata": {
        "id": "m8Hc9fZ-5UC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qda_predictions = predict_model( qda,df_chunk.drop(columns = ['uuid', 'name', 'firstregion', 'rechargetypeidcp', 'secondprovince','secondregion']))\n",
        "lr_predictions = predict_model( lr,df_chunk.drop(columns=['uuid', 'ussdid']))\n",
        "catboost_predictions = model.predict(CP_chunk_processed)"
      ],
      "metadata": {
        "id": "NotaVoeG5UYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Select tourists of size 109,237"
      ],
      "metadata": {
        "id": "Kdzt3z-r6QLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qda_predictions[qda_predictions['prediction_score']==1].filter(items=['uuid', 'prediction_score']).shape\n",
        "\n",
        "lr_predictions[lr_predictions['prediction_score']>=0.9755].filter(items=['uuid', 'prediction_score'])\n",
        "\n",
        "lr_predictions[lr_predictions['prediction_score']>=0.9755].filter(items=['uuid', 'prediction_score']).to_csv('/content/drive/My Drive/campagin.csv')"
      ],
      "metadata": {
        "id": "5E5ee3eP6NFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Select random of Customet profile of same size"
      ],
      "metadata": {
        "id": "l9_EAEq_6gG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.random.choice(lr_predictions.uuid, 109237)\n",
        "savetxt('/content/drive/My Drive/campagin_random.csv', data, delimiter=',', fmt='%s')"
      ],
      "metadata": {
        "id": "EUU23kw76geH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}